# -*- coding: utf-8 -*-
"""Fintech_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
	https://colab.research.google.com/drive/1ALhmoMmZS9EnP9Ia1P4Xq3KHBywivpFo
"""

pip install https://github.com/matplotlib/mpl_finance/archive/master.zip

# Commented out IPython magic to ensure Python compatibility.
!wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz
!tar -xzvf ta-lib-0.4.0-src.tar.gz
# %cd ta-lib
!./configure --prefix=/usr
!make
!make install
!pip install Ta-Lib

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import time
import csv
import talib, math
import keras
import keras.models
import keras.callbacks
import mpl_finance as mpf
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.models import Sequential
from keras.layers import SimpleRNN, LSTM, GRU, Activation, Dense, Dropout, Input, Embedding, Bidirectional, TimeDistributed
from keras.optimizers import Adam
from keras.layers.normalization import BatchNormalization

from sklearn import preprocessing
from sklearn.metrics import mean_squared_error

from google.colab import files

def data_produce(stock_path, covid_path, file_name):
	# stock_path = 'Germany_DAX_stock.csv'
	# covid_path = 'Germany_covid.csv'

	stock = pd.read_csv(stock_path)
	covid = pd.read_csv(covid_path)
	stock.drop('Adj Close', axis=1, inplace=True)
	ma10 = talib.SMA(np.array(stock['Close']),10)
	ma30 = talib.SMA(np.array(stock['Close']),30)

	stock['ma10'], stock['ma30'] = ma10, ma30
	stock['K'], stock['D'] = talib.STOCH(stock['High'],stock['Low'],stock['Close'])
	stock.fillna(value=0,inplace=True)

	covid = covid_preprocess(covid)
	stock = stock_preprocess(stock)

	stock = stock[(stock['Date'] >= "2020-02-01") & (stock['Date'] <= "2020-11-30")]
	covid = covid[(covid['Date'] >= "2020-02-01") & (covid['Date'] <= "2020-11-30")]

	stock = stock.reset_index(drop=True)
	covid = covid.reset_index(drop=True)

	df = merge_pd(stock, covid)
	# file_name = 'Germany_data.csv'
	df.to_csv("%s"%file_name,index=False)

def covid_preprocess(covid_pd):

	covid_pd = covid_pd.rename(columns = {'date': 'Date'}, inplace = False)

	features = list(covid_pd.columns)
	# print('features',features)

	features = features[:2]
	covid_pd = covid_pd[features]

	covid_pd = covid_pd.dropna()

	for i in range(len(covid_pd['Date'])):
		# print(covid_pd.loc[i,'Date'])
		temp = covid_pd.loc[i,'Date']
		temp = time.strptime(temp, "%Y/%m/%d")
		nt = time.strftime("%Y-%m-%d", temp)
		# print(nt)
		covid_pd.loc[i,'Date'] = nt

	return covid_pd

def stock_preprocess(stock_pd):

	stock_pd['Date'] = pd.to_datetime(stock_pd['Date'])
	
	for i in range(len(stock_pd['Date'])):
		temp = stock_pd.loc[i,'Date']
		temp = str(temp).split(' ')[0]
		stock_pd.loc[i,'Date'] = temp

	return stock_pd

def merge_pd(stock_pd, covid_pd):

	case = 0
	case_list = []
	for idx_c, date_c in enumerate(list(covid_pd['Date'])):
		case = case + int(covid_pd.loc[idx_c, "confirmed_cases"])
		if date_c in list(stock_pd['Date']):
			# print(idx_c, date_c)
			case_list.append(case)
			case = 0
		else:
			# case = case + covid_pd.loc[idx_c, "confirmed_cases"]
			pass
	stock_pd["covid"]=case_list
	return stock_pd

def normalize(df):
  norm = df.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))
  return norm

def gen_input_data(data, time_step = 5, future_day = 1):

	data_date = data["Date"]
	# print(data_date)
	data = data.drop(["Date"], axis = 1)
	date_list = []
	train_x, train_y = [], []
	for i in range(data.shape[0]-time_step):
		# print(data_date[i])
		date_list.append(data_date[i+time_step])
		train_x.append(np.array(data.iloc[i:i+time_step]))
		train_y.append(np.array(data.iloc[i+time_step:i+time_step+future_day]["Close"]))
	return np.array(train_x), np.array(train_y), date_list

def shuffle(X,Y):
	np.random.seed(10)
	randomList = np.arange(X.shape[0])
	np.random.shuffle(randomList)
	return X[randomList], Y[randomList]

def split_data(Date, date_list):
	target_date = 0
	for idx, d in enumerate(date_list):
		if d > Date:
			target_date = idx
			break

	x_val = x[target_date:]
	y_val = y[target_date:]
	x_train = x[:target_date]
	y_train = y[:target_date]
	return x_train, y_train, x_val, y_val

"""# 一、BDLSTM"""

"""## 0、 Combine data with covid and stock"""

# data_produce('Australia_stock.csv', 'Australia_covid.csv', 'Australia_data.csv')
# data_produce('Germany_stock.csv', 'Germany_covid.csv', 'Germany_data.csv')


"""## 1、 Generate training dataset"""

df = pd.read_csv('Germany_data.csv')
# df.drop('Volume',axis=1,inplace=True)

scaler_c = preprocessing.MinMaxScaler()
scaler_c.fit(df['Close'].values.reshape(-1,1))

df.iloc[:,start:end] = normalize(df.iloc[:,1:11])	#start = 1, end = 11

x, y, date_list = gen_input_data(df ,time_step = 5)

x_train, y_train, x_val, y_val = split_data("2020-09-30", date_list)

x_train, y_train = shuffle(x_train, y_train)


"""## 2、Model"""
def BDLSTM_model(shape):
	
	model = Sequential()
	forward_layer = LSTM(128, return_sequences=False)
	backward_layer = LSTM(128, activation='relu', return_sequences=False, go_backwards=True)
	model.add(Bidirectional(forward_layer, backward_layer=backward_layer, input_shape=(shape[1], shape[2])))
	model.add(Dense(1))
	# model.add(Activation('softmax'))
	model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])
	model.summary()
	return model

def BDLSTM_model_2(shape):
  model = Sequential()
  model.add(Bidirectional(LSTM(units=64,return_sequences=True),input_shape=(shape[1], shape[2])))
  model.add(Bidirectional(LSTM(units=32)))
  # forward_layer = LSTM(64, return_sequences=False)
  # backward_layer = LSTM(64, activation='relu', return_sequences=False, go_backwards=True)
  # model.add(Bidirectional(forward_layer, backward_layer=backward_layer, input_shape=(shape[1], shape[2])))
  # model.add(Dropout(0.2))
  # model.add(BatchNormalization())
  # model.add(TimeDistributed(Dense(1, activation='sigmoid')))
  
  model.add(Dense(1))
  # model.add(Activation('softmax'))
  model.compile(loss='mse', optimizer='adam')
  model.summary()
  return model

def BDLSTM_model_3(shape):
	
  model = Sequential()
  forward_layer = LSTM(128, return_sequences=False)
  backward_layer = LSTM(128, activation='relu', return_sequences=False, go_backwards=True)
  model.add(Bidirectional(forward_layer, backward_layer=backward_layer, input_shape=(shape[1], shape[2])))
  model.add(Dense(1))
  # model.add(Activation('softmax'))
  model.compile(loss='mse', optimizer='adam')
  model.summary()
  return model

model_BDLSTM = BDLSTM_model(x_train.shape)
# model_BDLSTM = BDLSTM_model_2(x_train.shape)
# model_BDLSTM = BDLSTM_model_3(x_train.shape)


"""## 3、Train"""

callback = EarlyStopping(monitor="loss", patience=10, verbose=1, mode="auto")
history_BDLSTM = model_BDLSTM.fit(x_train, y_train, epochs = 1000, batch_size = 64, validation_split=0.2, callbacks=[callback])

loss_BDLSTM = history_BDLSTM.history['loss']
val_loss_BDLSTM = history_BDLSTM.history['val_loss']
epochs_BDLSTM = range(1, len(loss_BDLSTM) + 1)

plt.plot(epochs_BDLSTM, loss_BDLSTM, label='Training loss')
plt.plot(epochs_BDLSTM, val_loss_BDLSTM, label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()


"""## 4、 Predict"""

vy = y_val.reshape((-1,))
vy_origin = scaler_c.inverse_transform(y_val)

predict_BDLSTM = model_BDLSTM.predict(x_val)

py_BDLSTM_origin = scaler_c.inverse_transform(predict_BDLSTM)

mse_BDLSTM = mean_squared_error(vy, predict_BDLSTM)
print('mse_BDLSTM:',mse_BDLSTM)

mse_BDLSTM_org = mean_squared_error(vy_origin, py_BDLSTM_origin)
print('mse_BDLSTM_org:',mse_BDLSTM_org)

plt.plot(vy_origin, color = 'red', label = 'Real Stock Index')  # 紅線表示真實股價
plt.plot(py_BDLSTM_origin, color = 'blue', label = 'Predicted Stock Index')  # 藍線表示預測股價
plt.title('MSE = ' + str(mse_BDLSTM_org))
plt.xlabel('Time')
plt.ylabel('Stock Price')
plt.legend()
plt.show()

# np.save('BDLSTM',py_BDLSTM_origin)
# files.download('BDLSTM.npy')

# np.save('vy_origin',vy_origin)
# files.download('vy_origin.npy')


##########################################################################################

"""# 二、LSTM_DNN"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.utils.data as Data
import torch.optim as optim
import matplotlib.pyplot as plt
import time
from sklearn.metrics import mean_squared_error as mse

def normalization(df):
	#df.drop('Date',axis=1,inplace=True)
	col = df.columns.drop('Date')
	for x in col:
		mini = min(df[x])
		maxi = max(df[x])
		if x == 'Close':
			close_max = maxi
			close_min = mini
		df[x] = (df[x] - mini)/(maxi - mini)
	return df, close_max, close_min

def gen_input_data(data, time_step = 5, future_day = 1):

	data_date = data["Date"]
	# print(data_date)
	data = data.drop(["Date"], axis = 1)
	date_list = []
	train_x, train_y = [], []
	for i in range(data.shape[0]-time_step):
		# print(data_date[i])
		date_list.append(data_date[i+time_step])
		train_x.append(np.array(data.iloc[i:i+time_step]))
		train_y.append(np.array(data.iloc[i+time_step:i+time_step+future_day]["Close"]))
	return np.array(train_x), np.array(train_y), date_list

def shuffle(X,Y):
	np.random.seed(10)
	randomList = np.arange(X.shape[0])
	np.random.shuffle(randomList)
	return X[randomList], Y[randomList]


"""## 1、 Generate training dataset"""

df = pd.read_csv('Germany_data.csv')
# df.drop('Volume',axis=1,inplace=True)
df = df[(df['Date'] >= "2020-02-01") & (df['Date'] <= "2020-11-30")]

df_norm,  close_max, close_min  = normalization(df.copy())
df_norm = df_norm.reset_index(drop=True)

train_x, train_y, date_list = gen_input_data(df_norm,5)

train_x, train_y, valid_x, valid_y = split_data("2020-09-30", date_list)

train_x, train_y = shuffle(train_x, train_y)

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
X_valid = torch.tensor(valid_x,dtype=torch.float32).to(device)
X_train = torch.tensor(train_x,dtype=torch.float32).to(device)
y_valid = torch.tensor(valid_y,dtype=torch.float32).to(device)
y_train = torch.tensor(train_y,dtype=torch.float32).to(device)


"""## 2、Model"""

class LSTM(nn.Module):
	def __init__(self,input_size, hidden_size, n_layers=1, output_size=1):
		super().__init__()
		self.hidden_size = hidden_size
		self.n_layers = n_layers
		self.lstm0 = nn.LSTM(input_size, hidden_size, n_layers, batch_first=True)  
		self.lstm1 = nn.LSTM(hidden_size, hidden_size, n_layers, batch_first=True)
		self.lstm2 = nn.LSTM(hidden_size, hidden_size, n_layers, batch_first=True)
		self.fc = nn.Linear(hidden_size, output_size)
	
	def forward(self, x):
		h0 = torch.zeros(self.n_layers, x.size(0), self.hidden_size).to(device).requires_grad_()
		c0 = torch.zeros(self.n_layers, x.size(0), self.hidden_size).to(device).requires_grad_()
		r_out0, (hidden_state, c) = self.lstm0(x,(h0.detach(),c0.detach()))
		h1 = torch.zeros(self.n_layers, x.size(0), self.hidden_size).to(device).requires_grad_()
		c1 = torch.zeros(self.n_layers, x.size(0), self.hidden_size).to(device).requires_grad_()
		r_out1, (hidden_state1, c1) = self.lstm1(r_out0,(h1.detach(),c1.detach()))
		h2 = torch.zeros(self.n_layers, x.size(0), self.hidden_size).to(device).requires_grad_()
		c2 = torch.zeros(self.n_layers, x.size(0), self.hidden_size).to(device).requires_grad_()
		r_out2, (hidden_state2, c2) = self.lstm2(r_out1,(h2.detach(),c2.detach()))
		outs = []
		for time in range(r_out1.size(1)):
			o = self.fc(r_out2[:, time, :].reshape(-1,self.hidden_size))
			outs.append(o[:].reshape(r_out2.shape[0],-1))
		return torch.stack(outs, dim=1)

"""## 3、Train"""

input_size = 10
hidden_size = 64
n_layers = 2
output_size = 1
lstm = LSTM(input_size, hidden_size, n_layers, output_size)

epoch = 100
loss_f = nn.MSELoss()
lr = 0.01
optimizer = optim.Adam(lstm.parameters(), lr=lr)
lstm.to(device)
lstm_train_loss, lstm_valid_loss = [], []

for i in range(1,epoch+1):
	print("epoch: {}/{}".format(i,epoch), end = '')
	optimizer.zero_grad()
	lstm_output = lstm(X_train)
	lstm_loss = loss_f(lstm_output[:,time_step-1,0].reshape(-1,1),y_train)
	lstm_train_loss.append(lstm_loss.item())
	print(", train loss: {: 4f}".format(lstm_loss.item()), end='')
	lstm_loss.backward()
	optimizer.step()
	
	with torch.no_grad():
		lstm_output2 = lstm(X_valid)
		lstm_v_loss = loss_f(lstm_output2[:,time_step-1,0].reshape(-1,1), y_valid)
		print(", validation loss: {:4f}.".format(lstm_v_loss.item()))
		lstm_valid_loss.append(lstm_v_loss.item())


"""## 4、 Predict"""

predict = lstm_output2[:,time_step-1,0].detach().cpu().numpy().reshape(-1,1)
predict = predict * (close_max - close_min) + close_min
real_index = np.array(df.loc[target_date + time_step:, 'Close']).reshape(-1,1)

mserr = mse(predict, real_index)

plt.plot(predict,color='b',label='predicted')
plt.plot(real_index,color='r',label='real')
plt.legend()
plt.title(f'Stock Index, MSE = {round(mserr,2)}')
# plt.savefig('Australia_DNN_LSTM.png')
plt.show()
fig = plt.figure()
plt.plot(lstm_train_loss,color='r',label='train loss')
plt.plot(lstm_valid_loss,color='b',label='validation loss')
plt.legend()
plt.title('Loss')
plt.xlabel('epoch')
# plt.savefig('Australia_DNN_lstm_loss.png')
plt.show()

# np.save('DNN',predict)
# files.download('DNN.npy')


##########################################################################################

"""# 三、PLOT with two model"""

import numpy as np
import matplotlib.pyplot as plt

"""Three_line_plot"""

real = np.load('Australia.npy')
BDLSTM = np.load('Australia_BDLSTM.npy')
DNN = np.load('Australia_DNN.npy')

mse_BDLSTM = mean_squared_error(real, BDLSTM)
print(mse_BDLSTM)

mse_DNN = mean_squared_error(real, DNN)
print(mse_DNN)

plt.plot(real, color = 'red', label = 'Real')  # 紅線表示真實股價
plt.plot(BDLSTM, color = 'blue', label = 'BDLSTM')  # 藍線表示預測股價
plt.plot(DNN, color = 'green', label = 'DNN-LSTM')  # 藍線表示預測股價
plt.title('Australia')
plt.xlabel('Time')
plt.ylabel('Stock Price')
plt.legend()
plt.savefig('Australia.png')
files.download('Australia.png')
plt.show()

